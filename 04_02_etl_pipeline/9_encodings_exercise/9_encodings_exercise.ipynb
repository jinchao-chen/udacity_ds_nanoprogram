{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encodings\n",
    "\n",
    "Encodings are a set of rules mapping string characters to their binary representations. Python supports dozens of different encoding as seen here in [this link](https://docs.python.org/3/library/codecs.html#standard-encodings). Because the web was originally in English, the first encoding rules mapped binary code to the English alphabet. \n",
    "\n",
    "The English alphabet has only 26 letters. But other languages have many more characters including accents, tildes and umlauts. As time went on, more encodings were invented to deal with languages other than English. The utf-8 standard tries to provide a single encoding schema that can encompass all text.\n",
    "\n",
    "The problem is that it's difficult to know what encoding rules were used to make a file unless somebody tells you. The most common encoding by far is utf-8. Pandas will assume that files are utf-8 when you read them in or write them out.\n",
    "\n",
    "Run the code cell below to read in the population data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/population_data.csv', skiprows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas should have been able to read in this data set without any issues. Next, run the code cell below to read in the 'mystery.csv' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-46474c2a2e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mystery.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('mystery.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have gotten an error: **UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte**. This means pandas assumed the file had a utf-8 encoding but had trouble reading in the data file. \n",
    "\n",
    "Your job in the next cell is to figure out the encoding for the mystery.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out what the encoding is of the myster.csv file\n",
    "# HINT: pd.read_csv('mystery.csv', encoding=?) where ? is the string for an encoding like 'ascii'\n",
    "# HINT: This link has a list of encodings that Python recognizes https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "\n",
    "# Python has a file containing a dictionary of encoding names and associated aliases\n",
    "# This line imports the dictionary and then creates a set of all available encodings\n",
    "# You can use this set of encodings to search for the correct encoding\n",
    "# If you'd like to see what this file looks like, execute the following Python code to see where the file is located\n",
    "#    from encodings import aliases\n",
    "#    aliases.__file__\n",
    "\n",
    "from encodings.aliases import aliases\n",
    "\n",
    "alias_values = set(aliases.values())\n",
    "\n",
    "# TODO: iterate through the alias_values list trying out the different encodings to see which one or ones work\n",
    "# HINT: Use a try - except statement. Otherwise your code will produce an error when reading in the csv file\n",
    "#       with the wrong encoding.\n",
    "# HINT: In the try statement, print out the encoding name so that you know which one(s) worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mac_latin2 is not the correct encoding\n",
      "utf_32_le is not the correct encoding\n",
      "kz1048 is not the correct encoding\n",
      "cp866 is not the correct encoding\n",
      "iso8859_3 is not the correct encoding\n",
      "cp858 is not the correct encoding\n",
      "utf_7 is not the correct encoding\n",
      "iso8859_13 is not the correct encoding\n",
      "congraultaions, cp037 is the correct encoding\n",
      "latin_1 is not the correct encoding\n",
      "koi8_r is not the correct encoding\n",
      "cp869 is not the correct encoding\n",
      "cp775 is not the correct encoding\n",
      "utf_32_be is not the correct encoding\n",
      "cp950 is not the correct encoding\n",
      "cp949 is not the correct encoding\n",
      "cp852 is not the correct encoding\n",
      "cp857 is not the correct encoding\n",
      "uu_codec is not the correct encoding\n",
      "bz2_codec is not the correct encoding\n",
      "cp863 is not the correct encoding\n",
      "utf_32 is not the correct encoding\n",
      "cp1250 is not the correct encoding\n",
      "base64_codec is not the correct encoding\n",
      "iso8859_7 is not the correct encoding\n",
      "congraultaions, cp1140 is the correct encoding\n",
      "iso8859_9 is not the correct encoding\n",
      "cp1258 is not the correct encoding\n",
      "iso2022_jp_2 is not the correct encoding\n",
      "rot_13 is not the correct encoding\n",
      "cp861 is not the correct encoding\n",
      "big5 is not the correct encoding\n",
      "euc_jis_2004 is not the correct encoding\n",
      "cp1251 is not the correct encoding\n",
      "iso8859_10 is not the correct encoding\n",
      "mac_turkish is not the correct encoding\n",
      "iso8859_5 is not the correct encoding\n",
      "iso8859_4 is not the correct encoding\n",
      "gbk is not the correct encoding\n",
      "cp1257 is not the correct encoding\n",
      "iso8859_6 is not the correct encoding\n",
      "iso8859_2 is not the correct encoding\n",
      "shift_jisx0213 is not the correct encoding\n",
      "mac_roman is not the correct encoding\n",
      "tactis is not the correct encoding\n",
      "cp855 is not the correct encoding\n",
      "congraultaions, cp500 is the correct encoding\n",
      "cp850 is not the correct encoding\n",
      "cp1253 is not the correct encoding\n",
      "mac_greek is not the correct encoding\n",
      "johab is not the correct encoding\n",
      "cp862 is not the correct encoding\n",
      "utf_8 is not the correct encoding\n",
      "cp1252 is not the correct encoding\n",
      "iso8859_15 is not the correct encoding\n",
      "big5hkscs is not the correct encoding\n",
      "shift_jis is not the correct encoding\n",
      "cp1256 is not the correct encoding\n",
      "gb2312 is not the correct encoding\n",
      "ascii is not the correct encoding\n",
      "congraultaions, cp273 is the correct encoding\n",
      "cp1255 is not the correct encoding\n",
      "euc_kr is not the correct encoding\n",
      "cp1125 is not the correct encoding\n",
      "mac_cyrillic is not the correct encoding\n",
      "shift_jis_2004 is not the correct encoding\n",
      "iso8859_11 is not the correct encoding\n",
      "cp437 is not the correct encoding\n",
      "congraultaions, cp1026 is the correct encoding\n",
      "iso2022_jp_ext is not the correct encoding\n",
      "iso8859_14 is not the correct encoding\n",
      "ptcp154 is not the correct encoding\n",
      "cp1254 is not the correct encoding\n",
      "iso2022_kr is not the correct encoding\n",
      "euc_jp is not the correct encoding\n",
      "congraultaions, utf_16_be is the correct encoding\n",
      "cp932 is not the correct encoding\n",
      "quopri_codec is not the correct encoding\n",
      "tis_620 is not the correct encoding\n",
      "euc_jisx0213 is not the correct encoding\n",
      "iso8859_16 is not the correct encoding\n",
      "zlib_codec is not the correct encoding\n",
      "hex_codec is not the correct encoding\n",
      "hp_roman8 is not the correct encoding\n",
      "iso2022_jp_2004 is not the correct encoding\n",
      "iso2022_jp_1 is not the correct encoding\n",
      "cp864 is not the correct encoding\n",
      "congraultaions, utf_16 is the correct encoding\n",
      "mbcs is not the correct encoding\n",
      "iso2022_jp_3 is not the correct encoding\n",
      "cp424 is not the correct encoding\n",
      "cp865 is not the correct encoding\n",
      "hz is not the correct encoding\n",
      "iso2022_jp is not the correct encoding\n",
      "mac_iceland is not the correct encoding\n",
      "cp860 is not the correct encoding\n",
      "iso8859_8 is not the correct encoding\n",
      "congraultaions, utf_16_le is the correct encoding\n",
      "gb18030 is not the correct encoding\n"
     ]
    }
   ],
   "source": [
    "applicable_encoding = []\n",
    "for alias_value in alias_values:\n",
    "    try:\n",
    "        df = pd.read_csv('mystery.csv', encoding= alias_value)\n",
    "        print('congraultaions, {:} is the correct encoding'.format(alias_value))\n",
    "        applicable_encoding.append(alias_value)\n",
    "    except:\n",
    "        print('{:} is not the correct encoding'.format(alias_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp037',\n",
       " 'cp1140',\n",
       " 'cp500',\n",
       " 'cp273',\n",
       " 'cp1026',\n",
       " 'utf_16_be',\n",
       " 'utf_16',\n",
       " 'utf_16_le']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applicable_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "There are dozens of encodings that Python can handle; however, Pandas assumes a utf-8 encoding. This makes sense since utf-8 is very common. However, you will sometimes come across files with other encodings. If you don't know the encoding, you have to search for it.\n",
    "\n",
    "Note, as always, there is a solution file for this exercise. Go to File->Open.\n",
    "\n",
    "There is a Python library that can be of some help when you don't know an encoding: chardet. Run the code cells below to see how it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in /Users/jinchaochen/opt/anaconda3/lib/python3.8/site-packages (3.0.4)\r\n"
     ]
    }
   ],
   "source": [
    "# install the chardet library\n",
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'UTF-16', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "# import the chardet library\n",
    "import chardet \n",
    "\n",
    "# use the detect method to find the encoding\n",
    "# 'rb' means read in the file as binary\n",
    "with open(\"mystery.csv\", 'rb') as file:\n",
    "    print(chardet.detect(file.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",Country Name,Country Code,Indicator Name,Indicator Code,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"mystery.csv\", encoding=\"utf-16\") as file:\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mystery.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>...</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>54211.0</td>\n",
       "      <td>55438.0</td>\n",
       "      <td>56225.0</td>\n",
       "      <td>56695.0</td>\n",
       "      <td>57032.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101353.0</td>\n",
       "      <td>101453.0</td>\n",
       "      <td>101669.0</td>\n",
       "      <td>102053.0</td>\n",
       "      <td>102577.0</td>\n",
       "      <td>103187.0</td>\n",
       "      <td>103795.0</td>\n",
       "      <td>104341.0</td>\n",
       "      <td>104822.0</td>\n",
       "      <td>105264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>8996351.0</td>\n",
       "      <td>9166764.0</td>\n",
       "      <td>9345868.0</td>\n",
       "      <td>9533954.0</td>\n",
       "      <td>9731361.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27294031.0</td>\n",
       "      <td>28004331.0</td>\n",
       "      <td>28803167.0</td>\n",
       "      <td>29708599.0</td>\n",
       "      <td>30696958.0</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>32758020.0</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>34656032.0</td>\n",
       "      <td>35530081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>5643182.0</td>\n",
       "      <td>5753024.0</td>\n",
       "      <td>5866061.0</td>\n",
       "      <td>5980417.0</td>\n",
       "      <td>6093321.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21759420.0</td>\n",
       "      <td>22549547.0</td>\n",
       "      <td>23369131.0</td>\n",
       "      <td>24218565.0</td>\n",
       "      <td>25096150.0</td>\n",
       "      <td>25998340.0</td>\n",
       "      <td>26920466.0</td>\n",
       "      <td>27859305.0</td>\n",
       "      <td>28813463.0</td>\n",
       "      <td>29784193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2947314.0</td>\n",
       "      <td>2927519.0</td>\n",
       "      <td>2913021.0</td>\n",
       "      <td>2905195.0</td>\n",
       "      <td>2900401.0</td>\n",
       "      <td>2895092.0</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "      <td>2873457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>AND</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>13411.0</td>\n",
       "      <td>14375.0</td>\n",
       "      <td>15370.0</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>17469.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83861.0</td>\n",
       "      <td>84462.0</td>\n",
       "      <td>84449.0</td>\n",
       "      <td>83751.0</td>\n",
       "      <td>82431.0</td>\n",
       "      <td>80788.0</td>\n",
       "      <td>79223.0</td>\n",
       "      <td>78014.0</td>\n",
       "      <td>77281.0</td>\n",
       "      <td>76965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>Kosovo</td>\n",
       "      <td>XKX</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>947000.0</td>\n",
       "      <td>966000.0</td>\n",
       "      <td>994000.0</td>\n",
       "      <td>1022000.0</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1747383.0</td>\n",
       "      <td>1761474.0</td>\n",
       "      <td>1775680.0</td>\n",
       "      <td>1791000.0</td>\n",
       "      <td>1805200.0</td>\n",
       "      <td>1824100.0</td>\n",
       "      <td>1821800.0</td>\n",
       "      <td>1801800.0</td>\n",
       "      <td>1816200.0</td>\n",
       "      <td>1830700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>YEM</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>5172135.0</td>\n",
       "      <td>5260501.0</td>\n",
       "      <td>5351799.0</td>\n",
       "      <td>5446063.0</td>\n",
       "      <td>5543339.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22356391.0</td>\n",
       "      <td>22974929.0</td>\n",
       "      <td>23606779.0</td>\n",
       "      <td>24252206.0</td>\n",
       "      <td>24909969.0</td>\n",
       "      <td>25576322.0</td>\n",
       "      <td>26246327.0</td>\n",
       "      <td>26916207.0</td>\n",
       "      <td>27584213.0</td>\n",
       "      <td>28250420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>17456855.0</td>\n",
       "      <td>17920673.0</td>\n",
       "      <td>18401608.0</td>\n",
       "      <td>18899275.0</td>\n",
       "      <td>19412975.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50412129.0</td>\n",
       "      <td>50970818.0</td>\n",
       "      <td>51584663.0</td>\n",
       "      <td>52263516.0</td>\n",
       "      <td>52998213.0</td>\n",
       "      <td>53767396.0</td>\n",
       "      <td>54539571.0</td>\n",
       "      <td>55291225.0</td>\n",
       "      <td>56015473.0</td>\n",
       "      <td>56717156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>3044846.0</td>\n",
       "      <td>3140264.0</td>\n",
       "      <td>3240587.0</td>\n",
       "      <td>3345145.0</td>\n",
       "      <td>3452942.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13082517.0</td>\n",
       "      <td>13456417.0</td>\n",
       "      <td>13850033.0</td>\n",
       "      <td>14264756.0</td>\n",
       "      <td>14699937.0</td>\n",
       "      <td>15153210.0</td>\n",
       "      <td>15620974.0</td>\n",
       "      <td>16100587.0</td>\n",
       "      <td>16591390.0</td>\n",
       "      <td>17094130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>263</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>Population, total</td>\n",
       "      <td>SP.POP.TOTL</td>\n",
       "      <td>3747369.0</td>\n",
       "      <td>3870756.0</td>\n",
       "      <td>3999419.0</td>\n",
       "      <td>4132756.0</td>\n",
       "      <td>4269863.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13558469.0</td>\n",
       "      <td>13810599.0</td>\n",
       "      <td>14086317.0</td>\n",
       "      <td>14386649.0</td>\n",
       "      <td>14710826.0</td>\n",
       "      <td>15054506.0</td>\n",
       "      <td>15411675.0</td>\n",
       "      <td>15777451.0</td>\n",
       "      <td>16150362.0</td>\n",
       "      <td>16529904.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Country Name Country Code     Indicator Name Indicator Code  \\\n",
       "0             0         Aruba          ABW  Population, total    SP.POP.TOTL   \n",
       "1             1   Afghanistan          AFG  Population, total    SP.POP.TOTL   \n",
       "2             2        Angola          AGO  Population, total    SP.POP.TOTL   \n",
       "3             3       Albania          ALB  Population, total    SP.POP.TOTL   \n",
       "4             4       Andorra          AND  Population, total    SP.POP.TOTL   \n",
       "..          ...           ...          ...                ...            ...   \n",
       "259         259        Kosovo          XKX  Population, total    SP.POP.TOTL   \n",
       "260         260   Yemen, Rep.          YEM  Population, total    SP.POP.TOTL   \n",
       "261         261  South Africa          ZAF  Population, total    SP.POP.TOTL   \n",
       "262         262        Zambia          ZMB  Population, total    SP.POP.TOTL   \n",
       "263         263      Zimbabwe          ZWE  Population, total    SP.POP.TOTL   \n",
       "\n",
       "           1960        1961        1962        1963        1964  ...  \\\n",
       "0       54211.0     55438.0     56225.0     56695.0     57032.0  ...   \n",
       "1     8996351.0   9166764.0   9345868.0   9533954.0   9731361.0  ...   \n",
       "2     5643182.0   5753024.0   5866061.0   5980417.0   6093321.0  ...   \n",
       "3     1608800.0   1659800.0   1711319.0   1762621.0   1814135.0  ...   \n",
       "4       13411.0     14375.0     15370.0     16412.0     17469.0  ...   \n",
       "..          ...         ...         ...         ...         ...  ...   \n",
       "259    947000.0    966000.0    994000.0   1022000.0   1050000.0  ...   \n",
       "260   5172135.0   5260501.0   5351799.0   5446063.0   5543339.0  ...   \n",
       "261  17456855.0  17920673.0  18401608.0  18899275.0  19412975.0  ...   \n",
       "262   3044846.0   3140264.0   3240587.0   3345145.0   3452942.0  ...   \n",
       "263   3747369.0   3870756.0   3999419.0   4132756.0   4269863.0  ...   \n",
       "\n",
       "           2008        2009        2010        2011        2012        2013  \\\n",
       "0      101353.0    101453.0    101669.0    102053.0    102577.0    103187.0   \n",
       "1    27294031.0  28004331.0  28803167.0  29708599.0  30696958.0  31731688.0   \n",
       "2    21759420.0  22549547.0  23369131.0  24218565.0  25096150.0  25998340.0   \n",
       "3     2947314.0   2927519.0   2913021.0   2905195.0   2900401.0   2895092.0   \n",
       "4       83861.0     84462.0     84449.0     83751.0     82431.0     80788.0   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "259   1747383.0   1761474.0   1775680.0   1791000.0   1805200.0   1824100.0   \n",
       "260  22356391.0  22974929.0  23606779.0  24252206.0  24909969.0  25576322.0   \n",
       "261  50412129.0  50970818.0  51584663.0  52263516.0  52998213.0  53767396.0   \n",
       "262  13082517.0  13456417.0  13850033.0  14264756.0  14699937.0  15153210.0   \n",
       "263  13558469.0  13810599.0  14086317.0  14386649.0  14710826.0  15054506.0   \n",
       "\n",
       "           2014        2015        2016        2017  \n",
       "0      103795.0    104341.0    104822.0    105264.0  \n",
       "1    32758020.0  33736494.0  34656032.0  35530081.0  \n",
       "2    26920466.0  27859305.0  28813463.0  29784193.0  \n",
       "3     2889104.0   2880703.0   2876101.0   2873457.0  \n",
       "4       79223.0     78014.0     77281.0     76965.0  \n",
       "..          ...         ...         ...         ...  \n",
       "259   1821800.0   1801800.0   1816200.0   1830700.0  \n",
       "260  26246327.0  26916207.0  27584213.0  28250420.0  \n",
       "261  54539571.0  55291225.0  56015473.0  56717156.0  \n",
       "262  15620974.0  16100587.0  16591390.0  17094130.0  \n",
       "263  15411675.0  15777451.0  16150362.0  16529904.0  \n",
       "\n",
       "[264 rows x 63 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded as traditional chinese\n",
    "df.to_csv('test.csv', encoding='big5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
